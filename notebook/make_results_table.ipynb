{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json, csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_from_JSON(JSON_input_file):\n",
    "    input_file = open(JSON_input_file, 'r')\n",
    "    input_JSON = ''.join(input_file.readlines())\n",
    "    data = json.loads(input_JSON)\n",
    "    input_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 files in input directory ../output_JSON/\n"
     ]
    }
   ],
   "source": [
    "input_path = \"../output_JSON/\"\n",
    "list_of_files = [f for f in listdir(input_path) if isfile(join(input_path, f))]\n",
    "print 'Found', len(list_of_files), 'files in input directory', input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_dict = {}\n",
    "common_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in sorted(list_of_files):\n",
    "    dictionary = read_data_from_JSON(input_path + file)\n",
    "    process = dictionary['process']\n",
    "    try:\n",
    "        initial_dict[process]\n",
    "    except:\n",
    "        initial_dict[process] = {}\n",
    "    for key in dictionary.keys():\n",
    "        if not \"process\" in key and not \"m_top\" in key:\n",
    "            try:\n",
    "                initial_dict[process][key].append(dictionary[key])\n",
    "            except:\n",
    "                initial_dict[process][key] = []\n",
    "                initial_dict[process][key].append(dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the common dictionary\n",
    "for process in initial_dict.keys():\n",
    "\tcommon_dictionary['xsection_' + process] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dict_key = next(iter(initial_dict))\n",
    "available_sub_keys = initial_dict[first_dict_key].keys()\n",
    "for key in available_sub_keys:\n",
    "    if not \"xsection\" in key and not \"m_top\" in key:\n",
    "        common_dictionary[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points = len(initial_dict[first_dict_key]['xsection'])\n",
    "for i in range(number_of_points):\n",
    "    for key in available_sub_keys:\n",
    "        value = initial_dict[first_dict_key][key][i]\n",
    "        value = round(value, 6)\n",
    "        if not \"xsection\" in key and not \"m_top\" in key:\n",
    "            common_dictionary[key].append(value)\n",
    "    for process in initial_dict.keys():\n",
    "        common_dictionary['xsection_' + process].append(initial_dict[process]['xsection'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_write = sorted(common_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('big_table.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys_to_write)\n",
    "    writer.writerows(zip(*[common_dictionary[key] for key in keys_to_write]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR,G_tot,a_r,g,mDM,mV,xsection_monotop,xsection_offshellV,xsection_onshellV,xsection_tt_exclusive\r",
      "\r\n",
      "0.01,0.030726,0.01,0.003403,1.0,1000.0,4.3297893e-06,1.353869e-08,6.353038e-05,2.0484385e-07\r",
      "\r\n",
      "0.1,0.033799,0.01,0.011288,1.0,1000.0,4.336242e-05,1.353869e-08,5.7807161e-05,2.0484385e-07\r",
      "\r\n",
      "0.2,0.038024,0.01,0.016932,1.0,1000.0,8.642885e-05,1.353869e-08,5.1310479e-05,2.0484385e-07\r",
      "\r\n",
      "0.3,0.043456,0.01,0.022169,1.0,1000.0,0.00012954021,1.353869e-08,4.4937276e-05,2.0484385e-07\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 big_table.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
